# Configuration for Haifa Bay Vessel Image Scraper - CONSERVATIVE FOR RELIABILITY

# Google Cloud Storage Configuration
gcs:
  bucket_name: outsource_data
  credentials_path: "./resources/credentials.json"
  
  # Paths within the bucket
  paths:
    # Where to save new scraped images
    upload_base: "reidentification/bronze/raw_crops/ship_spotting"
    
    # Where to check for existing IMOs (broader path to check all sources)
    check_base: "reidentification/bronze/raw_crops"

# API Configuration
api:
  datalastic_key: "b123dc58-4c18-4b0c-9f04-82a06be63ff9"
  
# Port Configuration (Haifa Bay)
port:
  name: "Haifa Bay"
  latitude: 32.8154
  longitude: 35.0043
  search_radius_km: 15

# Scraping Configuration - CONSERVATIVE FOR RELIABILITY
scraping:
  max_photos_per_imo: 150  # Or whatever you need
  max_gallery_pages: 10    # Good for finding all photos
  batch_size: 10           # Process 10 vessels at a time
  
  # Network settings - CONSERVATIVE
  connect_timeout: 10.0    # Enough time for connections
  read_timeout: 15.0       # Enough time for downloads
  max_retries: 3           # Standard retries
  retry_backoff_base: 1.0  # Standard backoff
  min_request_delay: 0.1   # Slightly increased for safety
  max_request_delay: 0.5   # More conservative
  
  # Concurrency settings - CONSERVATIVE FOR STABILITY
  gallery_workers: 4             # Good for cloudscraper
  image_download_workers: 10     # Reduced for stability
  max_concurrent_downloads: 10   # Reduced to prevent hanging
  
  # Image download settings
  stream_chunk_size: 8192       # Standard chunk size

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s [%(levelname)s] %(message)s"
  datefmt: "%H:%M:%S"